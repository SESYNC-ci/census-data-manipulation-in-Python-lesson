---
excerpt: Join and Summarize
---

## Join

The CBP dataset uses FIPS to identify U.S. counties and NAICS codes to identify
types of industry. The ACS dataset also uses FIPS but their data may aggregate
across multiple NAICS codes representing a single industry sector.

===

```{python handout = 0}
#sector <- fread(
#  'data/ACS/sector_naics.csv',
#  colClasses = c(NAICS='character'))
#sector =  pd.read_csv(
#  'data/ACS/sector_naics.csv',
#  dtype = {"NAICS": np.str})
sector =  pd.read_csv(
  'data/ACS/sector_naics.csv',
  dtype = {"NAICS": np.int64})
print(sector.dtypes)
print(cbp.dtypes)
cbp.head()
cbp.dtypes
cbp.head()
```
```{python eval = True}
print(sector.dtypes)
print(sector.shape) #24 economic sectors
sector.head()
#print(sector.shape)
```

Probably the primary challenge in combining secondary datasets for synthesis
research is dealing with their different sampling frames. A very common issue is
that data are collected at different "scales", with one dataset being at higher
spatial or temporal resolution than another. The differences between the CBP and
ACS categories of industry present a similar problem, and require the same
solution of re-aggregating data at the "lower resolution".
{:.notes}

===

### Many-to-One

```{python handout = 0}

#cbp = pd.read_csv(
#  'data/cbp15co.csv',
 # na_values = "NULL",
 # keep_default_na=False,
#  dtype = {"FIPSTATE": np.str, "FIPSCTY": np.str}
#  )

#cbp <- cbp %>%
#  inner_join(sector)
#cbp.head()
logical_idx = cbp['NAICS'].str.match('[0-9]{2}----')
cbp = cbp.loc[logical_idx]
cbp.head()
cbp.shape

#print(cbp.NAICS)
cbp['NAICS']= cbp.NAICS.apply(lambda x: np.int64(x[0:2]))
#print(cbp['NAICS'][0:1][0:2])

```

```{python}
#Many to one to join economic sector code to NAICS
print
cbp_test = cbp.merge(sector, on = "NAICS")
print(cbp_test.shape)
cbp_test.head()
print(cbp_test.shape)

cbp_test2 = cbp.merge(sector, on = "NAICS", how='inner')
cbp_test2.head()
print(cbp_test2.shape)

```

===

![]({% include asset.html path="images/many-to-one.svg" %}){:width="80%"}

The NAICS field in the `cbp` table can have the same value multiple times, it is
not a primary key in this table. In the `sector` table, the NAICS field is the
primary key uniquely identifying each record. The type of relationship between
these tables is therefore "many-to-one".
{:.notes}

===

Question
: Note that we lost a couple thousand rows through this join. How could
`cbp` have fewer rows after a join on NAICS codes?

Answer
: {:.fragment} The CBP data contains an NAICS code not mapped to a sector---the
"error code" 99 is not present in `sector`. The use of "error codes" that
could easilly be mistaken for data is frowned upon.

===

## Group By

A very common data manipulation procedure know as "split-apply-combine" tackles
the problem of applying the same transformation to subsets of data while keeping
the result all together. We need the total number of establishments
in each size class *aggregated within* each county and industry sector.

===

The pandas function `group_by` begins the process by indicating how the data
frame should be split into subsets.

```{python handout = 0}
#cbp_grouped <- cbp %>%
#  group_by(FIPS, Sector)

#cbp["FIPSTATE"]= cbp["FIPSTATE"].astype(str)
#cbp["FIPSCTY"]= cbp["FIPSCTY"].astype(str)

#cbp["FIPS"] = cbp["FIPSTATE"]+cbp["FIPSCTY"]

cbp_test = cbp.merge(sector, on = "NAICS")
#print(cbp_test.shape)
cbp_test.head()

cbp_grouped = cbp_test.groupby(['FIPS','Sector'])
#cbp_grouped = cbp.groupby(['Sector'])



```

===

At this point, nothing has really changed:

```{python}
#str(cbp_grouped)
cbp_grouped.dtypes
```

The `group_by` statement does not change any values in the data frame; it only
adds attributes to the the original data frame. You can add multiple variables
(separated by commas) in `group_by`; each distinct combination of values across
these columns defines a different group.
{:.notes}

===

## Summarize

The operation to perform on each group is summing: we need to sum the number of
establishments in each group. Using [dplyr](){:.rlib} functions, the summaries
are automically combined into a data frame.

===

```{python handout = 0}
#cbp <- cbp %>%
#  group_by(FIPS, Sector) %>%
#  select(starts_with('N'), -NAICS) %>%
#  summarize_all(sum)

test43 = (cbp_test.groupby(['FIPS', 'Sector']) 
                  #.filter(regex='^N)
                  #.filter(~['NAICS'])
                  .agg('sum'))
```

The "combine" part of "split-apply-combine" occurs automatically, when the
attributes introduced by `group_by` are dropped. You can see attributes either
by running the `str()` function on the data frame or by inspecting it in the
RStudio *Environment* pane.
{:.notes}

===

![]({% include asset.html path="images/one-to-one.svg" %}){:width="80%"}

There is now a one-to-one relationship between `cbp` and `acs`, based on
the combination of FIPS and Sector as the primary key for both tables.
{:.notes}

===

```{r handout = 0}
acs_cbp <- cbp %>%
  inner_join(acs)
```

Again, however, the one-to-one relationship does not mean all rows are preserved
by the join. The specific nature of the `inner_join` is to keep all rows, even
duplicating rows if the relationship is many-to-one, where there are matching
values in both tables, and discarding the rest.
{:.notes}

===

The `acs_cbp` table now includes the `median_income` variable from the ACS and
appropriatey aggregated establishment size information (the number of
establishments by employee bins) from the CBP table.

```{r eval = FALSE}
View(acs_cbp)
```
